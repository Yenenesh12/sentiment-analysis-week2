{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12ee63e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visual style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully\")\n",
    "<jupyter_output>\n",
    "<empty_output>\n",
    "<jupyter_text>\n",
    "1. Load Processed Data from Task 2\n",
    "<jupyter_code>\n",
    "# Load the processed data from Task 2\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "try:\n",
    "    # Try to load from multiple possible locations\n",
    "    file_paths = [\n",
    "        '../data/processed/processed_reviews.csv',\n",
    "        '../data/processed/processed_reviews_with_sentiment.csv',\n",
    "        'data/processed/processed_reviews.csv'\n",
    "    ]\n",
    "    \n",
    "    df = None\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(path)\n",
    "            print(f\"‚úÖ Data loaded from: {path}\")\n",
    "            print(f\"   Shape: {df.shape}\")\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if df is None:\n",
    "        # Create sample data if file doesn't exist\n",
    "        print(\"‚ö†Ô∏è No data file found. Creating sample data for demonstration.\")\n",
    "        np.random.seed(42)\n",
    "        n_samples = 1200\n",
    "        \n",
    "        sample_data = {\n",
    "            'bank_name': np.random.choice(['CBE', 'BOA', 'Dashen'], n_samples),\n",
    "            'review_text': [f\"Sample review {i}\" for i in range(n_samples)],\n",
    "            'rating': np.random.choice([1, 2, 3, 4, 5], n_samples, p=[0.1, 0.15, 0.25, 0.3, 0.2]),\n",
    "            'review_date': pd.date_range('2023-01-01', periods=n_samples).date,\n",
    "            'sentiment_label': np.random.choice(['positive', 'neutral', 'negative'], n_samples, p=[0.4, 0.3, 0.3]),\n",
    "            'sentiment_score': np.random.uniform(-1, 1, n_samples),\n",
    "            'cleaned_text': [f\"Cleaned review {i}\" for i in range(n_samples)]\n",
    "        }\n",
    "        df = pd.DataFrame(sample_data)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading data: {e}\")\n",
    "    raise\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nüìä DATA OVERVIEW:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total reviews: {len(df):,}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nüìà BASIC STATISTICS:\")\n",
    "print(\"=\"*50)\n",
    "print(df.describe(include='all'))\n",
    "<jupyter_output>\n",
    "<empty_output>\n",
    "<jupyter_text>\n",
    "2. Data Quality Assessment\n",
    "<jupyter_code>\n",
    "# Check for missing values\n",
    "print(\"üîç MISSING VALUES CHECK:\")\n",
    "print(\"=\"*50)\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Percentage': missing_percent\n",
    "})\n",
    "display(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nüìã DATA TYPES:\")\n",
    "print(\"=\"*50)\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check unique values for categorical columns\n",
    "print(\"\\nüéØ UNIQUE VALUES:\")\n",
    "print(\"=\"*50)\n",
    "categorical_cols = ['bank_name', 'sentiment_label']\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Unique values: {df[col].nunique()}\")\n",
    "        print(f\"  Value counts:\")\n",
    "        print(df[col].value_counts())\n",
    "<jupyter_output>\n",
    "<empty_output>\n",
    "<jupyter_text>\n",
    "3. Distribution Analysis\n",
    "<jupyter_code>\n",
    "# Create figure for distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Data Distribution Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Rating distribution\n",
    "ax1 = axes[0, 0]\n",
    "if 'rating' in df.columns:\n",
    "    rating_counts = df['rating'].value_counts().sort_index()\n",
    "    bars = ax1.bar(rating_counts.index.astype(str), rating_counts.values)\n",
    "    ax1.set_title('Rating Distribution (1-5)', fontweight='bold')\n",
    "    ax1.set_xlabel('Rating')\n",
    "    ax1.set_ylabel('Count')\n",
    "    \n",
    "    # Add counts on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 3,\n",
    "                f'{int(height)}', ha='center', va='bottom')\n",
    "\n",
    "# 2. Sentiment distribution\n",
    "ax2 = axes[0, 1]\n",
    "if 'sentiment_label' in df.columns:\n",
    "    sentiment_counts = df['sentiment_label'].value_counts()\n",
    "    colors = ['#4CAF50', '#FFC107', '#F44336']  # Green, Yellow, Red\n",
    "    ax2.pie(sentiment_counts.values, labels=sentiment_counts.index,\n",
    "            autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "    ax2.set_title('Sentiment Distribution', fontweight='bold')\n",
    "\n",
    "# 3. Bank distribution\n",
    "ax3 = axes[1, 0]\n",
    "if 'bank_name' in df.columns:\n",
    "    bank_counts = df['bank_name'].value_counts()\n",
    "    bars = ax3.bar(bank_counts.index, bank_counts.values)\n",
    "    ax3.set_title('Reviews per Bank', fontweight='bold')\n",
    "    ax3.set_xlabel('Bank')\n",
    "    ax3.set_ylabel('Number of Reviews')\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add counts on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2., height + 3,\n",
    "                f'{int(height)}', ha='center', va='bottom')\n",
    "\n",
    "# 4. Sentiment score distribution\n",
    "ax4 = axes[1, 1]\n",
    "if 'sentiment_score' in df.columns:\n",
    "    ax4.hist(df['sentiment_score'], bins=30, edgecolor='black', alpha=0.7)\n",
    "    ax4.set_title('Sentiment Score Distribution', fontweight='bold')\n",
    "    ax4.set_xlabel('Sentiment Score')\n",
    "    ax4.set_ylabel('Frequency')\n",
    "    ax4.axvline(x=0, color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "<jupyter_output>\n",
    "<empty_output>\n",
    "<jupyter_text>\n",
    "4. Bank Comparison Analysis\n",
    "<jupyter_code>\n",
    "print(\"üè¶ BANK COMPARISON ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'bank_name' in df.columns:\n",
    "    # Create comparison metrics\n",
    "    comparison_metrics = []\n",
    "    \n",
    "    for bank in df['bank_name'].unique():\n",
    "        bank_data = df[df['bank_name'] == bank]\n",
    "        \n",
    "        metrics = {\n",
    "            'Bank': bank,\n",
    "            'Total Reviews': len(bank_data),\n",
    "            'Avg Rating': bank_data['rating'].mean() if 'rating' in bank_data.columns else None,\n",
    "            'Avg Sentiment': bank_data['sentiment_score'].mean() if 'sentiment_score' in bank_data.columns else None,\n",
    "            'Positive %': (bank_data['sentiment_label'] == 'positive').mean() * 100 if 'sentiment_label' in bank_data.columns else None,\n",
    "            'Negative %': (bank_data['sentiment_label'] == 'negative').mean() * 100 if 'sentiment_label' in bank_data.columns else None,\n",
    "        }\n",
    "        comparison_metrics.append(metrics)\n",
    "    \n",
    "    # Create comparison DataFrame\n",
    "    comparison_df = pd.DataFrame(comparison_metrics)\n",
    "    \n",
    "    # Display comparison table\n",
    "    print(\"\\nüìä Performance Metrics by Bank:\")\n",
    "    display(comparison_df.style.background_gradient(subset=['Avg Rating', 'Avg Sentiment', 'Positive %'], cmap='RdYlGn'))\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    fig.suptitle('Bank Performance Comparison', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 1. Average Rating\n",
    "    ax1 = axes[0]\n",
    "    bars1 = ax1.bar(comparison_df['Bank'], comparison_df['Avg Rating'])\n",
    "    ax1.set_title('Average Rating', fontweight='bold')\n",
    "    ax1.set_ylabel('Rating (1-5)')\n",
    "    ax1.set_ylim(0, 5.5)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add values on bars\n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                f'{height:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 2. Positive Sentiment Percentage\n",
    "    ax2 = axes[1]\n",
    "    bars2 = ax2.bar(comparison_df['Bank'], comparison_df['Positive %'])\n",
    "    ax2.set_title('Positive Reviews Percentage', fontweight='bold')\n",
    "    ax2.set_ylabel('Percentage (%)')\n",
    "    ax2.set_ylim(0, 100)\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add values on bars\n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{height:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # 3. Total Reviews\n",
    "    ax3 = axes[2]\n",
    "    bars3 = ax3.bar(comparison_df['Bank'], comparison_df['Total Reviews'])\n",
    "    ax3.set_title('Total Number of Reviews', fontweight='bold')\n",
    "    ax3.set_ylabel('Count')\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add values on bars\n",
    "    for bar in bars3:\n",
    "        height = bar.get_height()\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2., height + 5,\n",
    "                f'{int(height)}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistical comparison\n",
    "    print(\"\\nüìà STATISTICAL COMPARISON:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if 'rating' in df.columns:\n",
    "        from scipy import stats\n",
    "        \n",
    "        banks = df['bank_name'].unique()\n",
    "        for i in range(len(banks)):\n",
    "            for j in range(i+1, len(banks)):\n",
    "                bank1_data = df[df['bank_name'] == banks[i]]['rating'].dropna()\n",
    "                bank2_data = df[df['bank_name'] == banks[j]]['rating'].dropna()\n",
    "                \n",
    "                if len(bank1_data) > 10 and len(bank2_data) > 10:\n",
    "                    t_stat, p_value = stats.ttest_ind(bank1_data, bank2_data, equal_var=False)\n",
    "                    print(f\"{banks[i]} vs {banks[j]}:\")\n",
    "                    print(f\"  t-statistic: {t_stat:.3f}, p-value: {p_value:.4f}\")\n",
    "                    if p_value < 0.05:\n",
    "                        print(f\"  ‚ö†Ô∏è  Significant difference in ratings (p < 0.05)\")\n",
    "                    else:\n",
    "                        print(f\"  ‚úÖ No significant difference in ratings\")\n",
    "                    print()\n",
    "<jupyter_output>\n",
    "<empty_output>\n",
    "<jupyter_text>\n",
    "5. Text Analysis & Word Clouds\n",
    "<jupyter_code>\n",
    "# Text analysis for each bank\n",
    "print(\"üìù TEXT ANALYSIS BY BANK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'review_text' in df.columns and 'bank_name' in df.columns:\n",
    "    for bank in df['bank_name'].unique():\n",
    "        print(f\"\\nüè¶ {bank}:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        bank_reviews = df[df['bank_name'] == bank]['review_text'].dropna()\n",
    "        \n",
    "        if len(bank_reviews) > 0:\n",
    "            # Calculate basic text statistics\n",
    "            review_lengths = bank_reviews.str.len()\n",
    "            word_counts = bank_reviews.str.split().str.len()\n",
    "            \n",
    "            print(f\"Total reviews: {len(bank_reviews)}\")\n",
    "            print(f\"Average characters per review: {review_lengths.mean():.0f}\")\n",
    "            print(f\"Average words per review: {word_counts.mean():.0f}\")\n",
    "            print(f\"Shortest review: {review_lengths.min()} chars\")\n",
    "            print(f\"Longest review: {review_lengths.max()} chars\")\n",
    "            \n",
    "            # Show sample reviews\n",
    "            print(f\"\\nSample Reviews:\")\n",
    "            for i, review in enumerate(bank_reviews.head(3)):\n",
    "                print(f\"  {i+1}. {review[:150]}...\" if len(review) > 150 else f\"  {i+1}. {review}\")\n",
    "\n",
    "# Generate word clouds\n",
    "print(\"\\n‚òÅÔ∏è WORD CLOUD GENERATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'review_text' in df.columns and 'bank_name' in df.columns:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    fig.suptitle('Word Clouds by Bank', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for idx, bank in enumerate(df['bank_name'].unique()):\n",
    "        ax = axes[idx]\n",
    "        bank_reviews = df[df['bank_name'] == bank]['review_text'].dropna()\n",
    "        \n",
    "        if len(bank_reviews) > 0:\n",
    "            # Combine all reviews\n",
    "            text = ' '.join(bank_reviews.astype(str))\n",
    "            \n",
    "            # Generate word cloud\n",
    "            wordcloud = WordCloud(\n",
    "                width=400,\n",
    "                height=300,\n",
    "                background_color='white',\n",
    "                max_words=100,\n",
    "                contour_width=2,\n",
    "                contour_color='steelblue'\n",
    "            ).generate(text)\n",
    "            \n",
    "            ax.imshow(wordcloud, interpolation='bilinear')\n",
    "            ax.set_title(f'{bank}\\n({len(bank_reviews)} reviews)', fontweight='bold')\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, 'No reviews available', \n",
    "                   ha='center', va='center', fontsize=12)\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "<jupyter_output>\n",
    "<empty_output>\n",
    "<jupyter_text>\n",
    "6. Sentiment Analysis Deep Dive\n",
    "<jupyter_code>\n",
    "print(\"üòä SENTIMENT ANALYSIS DEEP DIVE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'sentiment_label' in df.columns and 'rating' in df.columns:\n",
    "    # Create cross-tabulation of sentiment vs rating\n",
    "    sentiment_rating = pd.crosstab(df['sentiment_label'], df['rating'])\n",
    "    \n",
    "    print(\"\\nüìä Sentiment vs Rating Cross-tabulation:\")\n",
    "    display(sentiment_rating.style.background_gradient(cmap='Blues'))\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # 1. Heatmap of sentiment vs rating\n",
    "    ax1 = axes[0]\n",
    "    sns.heatmap(sentiment_rating, annot=True, fmt='d', cmap='YlOrRd', ax=ax1)\n",
    "    ax1.set_title('Sentiment vs Rating Distribution', fontweight='bold')\n",
    "    ax1.set_xlabel('Rating')\n",
    "    ax1.set_ylabel('Sentiment')\n",
    "    \n",
    "    # 2. Sentiment by bank\n",
    "    ax2 = axes[1]\n",
    "    if 'bank_name' in df.columns:\n",
    "        sentiment_by_bank = pd.crosstab(df['bank_name'], df['sentiment_label'], normalize='index') * 100\n",
    "        sentiment_by_bank.plot(kind='bar', stacked=True, ax=ax2, \n",
    "                              color=['#4CAF50', '#FFC107', '#F44336'])\n",
    "        ax2.set_title('Sentiment Distribution by Bank', fontweight='bold')\n",
    "        ax2.set_xlabel('Bank')\n",
    "        ax2.set_ylabel('Percentage (%)')\n",
    "        ax2.legend(title='Sentiment')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze sentiment-score relationship\n",
    "    if 'sentiment_score' in df.columns:\n",
    "        print(\"\\nüìà Sentiment Score Analysis:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Correlation between rating and sentiment score\n",
    "        correlation = df['rating'].corr(df['sentiment_score'])\n",
    "        print(f\"Correlation between rating and sentiment score: {correlation:.3f}\")\n",
    "        \n",
    "        if correlation > 0.5:\n",
    "            print(\"‚úÖ Strong positive correlation: Higher ratings correspond to more positive sentiment\")\n",
    "        elif correlation > 0.3:\n",
    "            print(\"‚ö†Ô∏è Moderate positive correlation\")\n",
    "        elif correlation > 0:\n",
    "            print(\"‚ö†Ô∏è Weak positive correlation\")\n",
    "        else:\n",
    "            print(\"‚ùå No or negative correlation - check sentiment analysis model\")\n",
    "<jupyter_output>\n",
    "<empty_output>\n",
    "<jupyter_text>\n",
    "7. Time Series Analysis (if dates available)\n",
    "<jupyter_code>\n",
    "print(\"üìÖ TIME SERIES ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'review_date' in df.columns:\n",
    "    # Convert to datetime\n",
    "    df['review_date'] = pd.to_datetime(df['review_date'], errors='coerce')\n",
    "    \n",
    "    # Filter out invalid dates\n",
    "    date_df = df.dropna(subset=['review_date'])\n",
    "    \n",
    "    if len(date_df) > 0:\n",
    "        # Resample by month\n",
    "        date_df.set_index('review_date', inplace=True)\n",
    "        \n",
    "        # Create monthly aggregates\n",
    "        monthly_stats = date_df.resample('M').agg({\n",
    "            'rating': 'mean',\n",
    "            'sentiment_score': 'mean'\n",
    "        })\n",
    "        \n",
    "        # Count reviews per month\n",
    "        monthly_counts = date_df.resample('M').size()\n",
    "        \n",
    "        # Create time series plot\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "        \n",
    "        # 1. Monthly review counts\n",
    "        ax1 = axes[0]\n",
    "        monthly_counts.plot(ax=ax1, marker='o', linewidth=2)\n",
    "        ax1.set_title('Monthly Review Volume', fontweight='bold')\n",
    "        ax1.set_xlabel('Month')\n",
    "        ax1.set_ylabel('Number of Reviews')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add trend line\n",
    "        try:\n",
    "            from scipy import stats\n",
    "            x = np.arange(len(monthly_counts))\n",
    "            y = monthly_counts.values\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "            trend_line = slope * x + intercept\n",
    "            ax1.plot(monthly_counts.index, trend_line, 'r--', alpha=0.7, \n",
    "                    label=f'Trend (slope: {slope:.2f})')\n",
    "            ax1.legend()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # 2. Monthly average rating and sentiment\n",
    "        ax2 = axes[1]\n",
    "        ax2.plot(monthly_stats.index, monthly_stats['rating'], \n",
    "                marker='o', linewidth=2, label='Average Rating')\n",
    "        ax2.set_xlabel('Month')\n",
    "        ax2.set_ylabel('Rating (1-5)', color='blue')\n",
    "        ax2.tick_params(axis='y', labelcolor='blue')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add sentiment on secondary axis\n",
    "        ax2_sentiment = ax2.twinx()\n",
    "        ax2_sentiment.plot(monthly_stats.index, monthly_stats['sentiment_score'], \n",
    "                          marker='s', linewidth=2, color='red', label='Average Sentiment')\n",
    "        ax2_sentiment.set_ylabel('Sentiment Score', color='red')\n",
    "        ax2_sentiment.tick_params(axis='y', labelcolor='red')\n",
    "        \n",
    "        # Combine legends\n",
    "        lines1, labels1 = ax2.get_legend_handles_labels()\n",
    "        lines2, labels2 = ax2_sentiment.get_legend_handles_labels()\n",
    "        ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "        \n",
    "        ax2.set_title('Monthly Average Rating and Sentiment', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print time-based insights\n",
    "        print(\"\\n‚è∞ TIME-BASED INSIGHTS:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Date range: {date_df.index.min().date()} to {date_df.index.max().date()}\")\n",
    "        print(f\"Total months of data: {len(monthly_counts)}\")\n",
    "        \n",
    "        # Busiest month\n",
    "        busiest_month = monthly_counts.idxmax()\n",
    "        print(f\"Busiest month: {busiest_month.strftime('%B %Y')} ({monthly_counts.max()} reviews)\")\n",
    "        \n",
    "        # Best rated month\n",
    "        if 'rating' in monthly_stats.columns:\n",
    "            best_month = monthly_stats['rating'].idxmax()\n",
    "            print(f\"Best rated month: {best_month.strftime('%B %Y')} (Rating: {monthly_stats['rating'].max():.2f})\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No valid date data available for time series analysis\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è 'review_date' column not found in dataset\")\n",
    "<jupyter_output>\n",
    "<empty_output>\n",
    "<jupyter_text>\n",
    "8. Preliminary Insights for Task 4\n",
    "<jupyter_code>\n",
    "print(\"üîç PRELIMINARY INSIGHTS FOR TASK 4\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize insights dictionary\n",
    "insights = {\n",
    "    'drivers': {},\n",
    "    'pain_points': {},\n",
    "    'recommendations': {}\n",
    "}\n",
    "\n",
    "# Analyze each bank separately\n",
    "if 'bank_name' in df.columns:\n",
    "    for bank in df['bank_name'].unique():\n",
    "        print(f\"\\nüè¶ ANALYSIS FOR {bank}:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        bank_data = df[df['bank_name'] == bank]\n",
    "        \n",
    "        # Drivers (from positive reviews)\n",
    "        positive_reviews = bank_data[bank_data['sentiment_label'] == 'positive']\n",
    "        if len(positive_reviews) > 0:\n",
    "            print(f\"\\n‚úÖ POTENTIAL SATISFACTION DRIVERS ({len(positive_reviews)} positive reviews):\")\n",
    "            \n",
    "            # Analyze common themes in positive reviews (simplified)\n",
    "            common_words = {}\n",
    "            if 'review_text' in positive_reviews.columns:\n",
    "                # Simple word frequency analysis\n",
    "                all_text = ' '.join(positive_reviews['review_text'].astype(str).str.lower())\n",
    "                words = all_text.split()\n",
    "                from collections import Counter\n",
    "                word_counts = Counter(words)\n",
    "                \n",
    "                # Filter out common stopwords\n",
    "                stopwords = {'the', 'and', 'to', 'of', 'a', 'in', 'is', 'it', 'that', 'for', 'on', 'with', 'as', 'this', 'by', 'i', 'not'}\n",
    "                meaningful_words = {word: count for word, count in word_counts.items() \n",
    "                                   if word not in stopwords and len(word) > 3}\n",
    "                \n",
    "                top_words = sorted(meaningful_words.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "                \n",
    "                print(\"  Top words in positive reviews:\")\n",
    "                for word, count in top_words:\n",
    "                    print(f\"    ‚Ä¢ '{word}': {count} mentions\")\n",
    "                \n",
    "                insights['drivers'][bank] = [word for word, _ in top_words[:3]]\n",
    "        \n",
    "        # Pain points (from negative reviews)\n",
    "        negative_reviews = bank_data[bank_data['sentiment_label'] == 'negative']\n",
    "        if len(negative_reviews) > 0:\n",
    "            print(f\"\\n‚ùå POTENTIAL PAIN POINTS ({len(negative_reviews)} negative reviews):\")\n",
    "            \n",
    "            if 'review_text' in negative_reviews.columns:\n",
    "                # Simple word frequency analysis\n",
    "                all_text = ' '.join(negative_reviews['review_text'].astype(str).str.lower())\n",
    "                words = all_text.split()\n",
    "                from collections import Counter\n",
    "                word_counts = Counter(words)\n",
    "                \n",
    "                # Filter out common stopwords\n",
    "                stopwords = {'the', 'and', 'to', 'of', 'a', 'in', 'is', 'it', 'that', 'for', 'on', 'with', 'as', 'this', 'by', 'i', 'not'}\n",
    "                meaningful_words = {word: count for word, count in word_counts.items() \n",
    "                                   if word not in stopwords and len(word) > 3}\n",
    "                \n",
    "                top_words = sorted(meaningful_words.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "                \n",
    "                print(\"  Top words in negative reviews:\")\n",
    "                for word, count in top_words:\n",
    "                    print(f\"    ‚Ä¢ '{word}': {count} mentions\")\n",
    "                \n",
    "                insights['pain_points'][bank] = [word for word, _ in top_words[:3]]\n",
    "        \n",
    "        # Preliminary recommendations\n",
    "        print(f\"\\nüí° PRELIMINARY RECOMMENDATIONS:\")\n",
    "        \n",
    "        # Based on rating analysis\n",
    "        if 'rating' in bank_data.columns:\n",
    "            avg_rating = bank_data['rating'].mean()\n",
    "            if avg_rating < 3.0:\n",
    "                print(\"  ‚ö†Ô∏è Urgent improvement needed - average rating below 3.0\")\n",
    "                print(\"    ‚Ä¢ Conduct user interviews to understand core issues\")\n",
    "                print(\"    ‚Ä¢ Prioritize bug fixes and stability improvements\")\n",
    "            elif avg_rating < 4.0:\n",
    "                print(\"  ‚ö†Ô∏è Room for improvement - average rating between 3.0-4.0\")\n",
    "                print(\"    ‚Ä¢ Address top pain points from negative reviews\")\n",
    "                print(\"    ‚Ä¢ Enhance existing features based on positive feedback\")\n",
    "            else:\n",
    "                print(\"  ‚úÖ Good performance - average rating above 4.0\")\n",
    "                print(\"    ‚Ä¢ Maintain quality and address minor issues\")\n",
    "                print(\"    ‚Ä¢ Consider adding new features requested by users\")\n",
    "        \n",
    "        # Based on review volume\n",
    "        total_reviews = len(bank_data)\n",
    "        if total_reviews < 300:\n",
    "            print(f\"  üìä Low review volume ({total_reviews} reviews)\")\n",
    "            print(\"    ‚Ä¢ Encourage more users to leave reviews\")\n",
    "            print(\"    ‚Ä¢ Implement in-app feedback prompts\")\n",
    "        \n",
    "        print()\n",
    "\n",
    "# Summary of insights\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã SUMMARY OF PRELIMINARY INSIGHTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for bank in df['bank_name'].unique() if 'bank_name' in df.columns else []:\n",
    "    print(f\"\\n{bank}:\")\n",
    "    if bank in insights['drivers']:\n",
    "        print(f\"  Drivers: {', '.join(insights['drivers'][bank])}\")\n",
    "    if bank in insights['pain_points']:\n",
    "        print(f\"  Pain Points: {', '.join(insights['pain_points'][bank])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ EXPLORATORY ANALYSIS COMPLETED\")\n",
    "print(\"=\"*60)\n",
    "<jupyter_output>\n",
    "<empty_output>\n",
    "<jupyter_text>\n",
    "9. Save Analysis Results\n",
    "<jupyter_code>\n",
    "# Save processed insights for Task 4\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "output_dir = '../reports/exploratory'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save insights\n",
    "insights_file = os.path.join(output_dir, 'preliminary_insights.json')\n",
    "with open(insights_file, 'w') as f:\n",
    "    json.dump(insights, f, indent=2)\n",
    "\n",
    "print(f\"üíæ Preliminary insights saved to: {insights_file}\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary_stats = {\n",
    "    'total_reviews': len(df),\n",
    "    'banks_analyzed': list(df['bank_name'].unique()) if 'bank_name' in df.columns else [],\n",
    "    'date_range': {\n",
    "        'start': str(df['review_date'].min()) if 'review_date' in df.columns else None,\n",
    "        'end': str(df['review_date'].max()) if 'review_date' in df.columns else None\n",
    "    } if 'review_date' in df.columns else None,\n",
    "    'average_rating': float(df['rating'].mean()) if 'rating' in df.columns else None,\n",
    "    'sentiment_distribution': dict(df['sentiment_label'].value_counts()) if 'sentiment_label' in df.columns else None\n",
    "}\n",
    "\n",
    "stats_file = os.path.join(output_dir, 'summary_statistics.json')\n",
    "with open(stats_file, 'w') as f:\n",
    "    json.dump(summary_stats, f, indent=2)\n",
    "\n",
    "print(f\"üìä Summary statistics saved to: {stats_file}\")\n",
    "\n",
    "# Save key visualizations\n",
    "visualization_dir = os.path.join(output_dir, 'visualizations')\n",
    "os.makedirs(visualization_dir, exist_ok=True)\n",
    "\n",
    "# Save the main comparison plot\n",
    "if 'bank_name' in df.columns:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    comparison_df[['Bank', 'Avg Rating', 'Positive %']].set_index('Bank').plot(kind='bar', ax=ax)\n",
    "    ax.set_title('Bank Performance Comparison', fontweight='bold')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(visualization_dir, 'bank_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"üìà Visualization saved to: {visualization_dir}/bank_comparison.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ EXPLORATORY ANALYSIS NOTEBOOK COMPLETED\")\n",
    "print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
